{"title":"Simple Linear Regression","markdown":{"yaml":{"title":"Simple Linear Regression","subtitle":"DKU Stats 101 Spring 2022","author":"Professor MacDonald","date":"1/24/2022","output":{"learnr::tutorial":{"toc_depth":2}},"runtime":"shiny_prerendered"},"headingText":"Linear model","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE)\nknitr::opts_chunk$set(warning = FALSE)\nknitr::opts_chunk$set(message = FALSE)\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(broom)\nlibrary(gridExtra)\nlibrary(learnr)\n\ntheme_set(theme_classic())\n\nclassroster <- read.csv(\"www/classroster.csv\", fileEncoding=\"UTF-8-BOM\")\n\nglobal.data <- read.csv(\"www/HDI.2015.csv\")\n\nglobal.data.nooutlier <- global.data %>%\n  filter(gdp.capita < 100000)\n\nglobal.data.log <- global.data %>%\n  mutate(log.gdp.capita = log(gdp.capita))\n\nhdi.model <- lm(hdi.score ~ gdp.capita, data=global.data)\nglobal.data.augmented <- augment(hdi.model, global.data)\nhdi.model.tidy <- tidy(hdi.model)\n\nhdi.model.nooutlier <- lm(hdi.score ~ gdp.capita, data=global.data.nooutlier)  \nglobal.data.augmented.nooutlier <- augment(hdi.model.nooutlier, global.data.nooutlier)\nhdi.model.tidy.nooutlier <- tidy(hdi.model.nooutlier)\n\nhdi.model.log <- lm(hdi.score ~ log.gdp.capita, data=global.data.log)\nglobal.data.augmented.log <- augment(hdi.model.log, global.data.log)\nhdi.model.tidy.log <- tidy(hdi.model.log)\n```\n\n\n## Line of best fit\n\n```{r hdi, fig.cap=\"HDI definition^[https://www.researchgate.net/figure/Structure-of-the-Human-Development-Index_fig1_23725014]\", out.width = \"600px\"}\nknitr::include_graphics(\"www/hdi.png\")\n```\n\nHow to describe the relationship between `GDP per capita` and `HDI score`?\n\nAs we learned:\n\n- Direction\n- Form\n- Strength\n- Outlier\n\nWhat do you expect the relationship between GDP per capita and HDI will be?\n\n```{r picker0, exercise=TRUE}\nsample(classroster$name, 1)\n```\n\n## Scatterplot of `GDP per capita` and `HDI`\n\n```{r scatterplot, exercise=TRUE}\nggplot(global.data, aes(x=gdp.capita, y=hdi.score)) +\n  geom_point() +\n  labs(x=\"GDP per capita\", y=\"Human Development Index (HDI) score\")\n```\n\n### Smoother\n\n```{r smoother, exercise=TRUE}\nggplot(global.data, aes(x=gdp.capita, y=hdi.score)) +\n  geom_point() +\n  labs(x=\"GDP per capita\", y=\"Human Development Index (HDI) score\") +\n  geom_smooth(se=FALSE)\n```\n\n### Taking a guess\n\nWhat do you think the intercept and the slope should be for a line of 'good' fit?\n\n```{r picker1, exercise=TRUE}\nsample(classroster$name, 1)\n```\n\n```{r guessingslope, exercise=TRUE}\nggplot(global.data, aes(x=gdp.capita, y=hdi.score)) +\n  geom_point() +\n  labs(x=\"GDP per capita\", y=\"Human Development Index (HDI) score\") +\n  geom_abline(intercept = 0, slope=0, color=\"blue\")\n```\n\n### Least squares line\n\n>Slope: `r format(hdi.model.tidy$estimate[2], scientific=FALSE)`, intercept: `r format(hdi.model.tidy$estimate[1], scientific=FALSE)` \n\n```{r leastsquares, exercise=TRUE}\nggplot(global.data, aes(x=gdp.capita, y=hdi.score)) +\n  geom_point() +\n  labs(x=\"GDP per capita\", y=\"Human Development Index (HDI) score\") +\n  geom_smooth(method=\"lm\", se=FALSE)\n\n```\n\n## Linear model\n\nIt's better if we come up with a more formal model: $\\hat{y}= b_0 + b_1x$\n\n$\\hat{y}$ is our predicted value\n$b_0$ is the $y$ intercept - the value when $x$ is 0\n$b_1$ is the slope\n\n- Helps with predictions\n  + For values not in the sample, we can estimate their `HDI score`\n- Helps assess model fit - we can compare different lines more easily\n  + More specifically we can calculate the **residuals**\n  + Residuals are difference between our line and the actually observed value - how much our line 'missed' by\n\n### Linear model for our data\n\n$\\hat{y}= `r format(hdi.model.tidy$estimate[1], scientific=FALSE)` + `r format(hdi.model.tidy$estimate[2], scientific=FALSE)`x$\n\n```{r leastsquares2, exercise=TRUE}\nggplot(global.data, aes(x=gdp.capita, y=hdi.score)) +\n  geom_point() +\n  labs(x=\"GDP per capita\", y=\"Human Development Index (HDI) score\") +\n  geom_smooth(method=\"lm\", se=FALSE)\n```\n\n## Least squares line\n\n- But how to calculate? \n- Many different ways\n  + Make a line minimizing the least absolute deviations\n  + Non-parametric lines\n  + Make a line minimizing the sum of the squares of the deviations\n- Least squares line is most common\n  + Advantages: \n    + Easy to calculate\n    + Well understood statistical properties\n  + Disadvantages: \n    + Line will be strongly influenced by outliers\n\n## Examining model fit\n\n- Checking the residuals\n- Residual standard deviation\n- $R^2$\n- Checking assumptions\n\n### Checking the residuals\n\nAll real datasets have noise so the real formula is:\n\n$y = b_0 + b_1x + e$\n\nResidual = Observed - Predicted\n  \n  + $e = y - \\hat{y}$\n\nCan easily plot the residuals, put the  \"size of the miss\" on the $y$ axis, and original data on the $x$ axis\n\n### Residuals - our data\n\n```{r dataresiduals, exercise=TRUE}\nggplot(global.data.augmented, aes(gdp.capita, hdi.score)) + \n  geom_point() + \n  geom_smooth(method=\"lm\", se=FALSE) +\n  geom_segment(aes(xend = gdp.capita, yend = .fitted), linetype=\"dashed\") + \n  labs(x=\"GDP per capita\", y=\"Human Development Index (HDI) score\") \n```\n\nHow would you interpret these residuals?\n\n```{r picker2, exercise=TRUE}\nsample(classroster$name, 1)\n```\n\n## Graphing the residuals\n\n```{r residualsplot, exercise=TRUE}\nggplot(global.data.augmented, aes(gdp.capita, .resid)) + \n  geom_point() + \n  geom_hline(yintercept = 0, color = \"blue\", linetype='dashed') + \n  labs(y = \"Residuals\", x=\"GDP per capita\")\n```\n\n### Residuals vs. original data\n\n```{r residualsvactual, exercise=TRUE}\noriginal <-\n  ggplot(global.data, aes(x=gdp.capita, y=hdi.score)) +\n  geom_point() +\n  labs(x=\"GDP per capita\", y=\"Human Development Index (HDI) score\") +\n  geom_smooth(method=\"lm\", se=FALSE)\n\nresids <- ggplot(global.data.augmented, aes(gdp.capita, .resid)) + \n  geom_point() + \n  geom_hline(yintercept = 0, color = \"blue\", linetype='dashed') + \n  labs(y = \"Residuals\", x=\"GDP per capita\")\n\ngrid.arrange(original, resids)\n```\n\n## Residual standard deviation\n\n- Since the residuals are just another distribution, we can also examine their distribution\n  + What to look for: symmetrical, no skew/outliers \n  + Standard deviation not too large\n\n### Residual standard deviation - our data\n\n```{r residualstddev, exercise=TRUE}\nggplot(global.data.augmented, aes(x=.resid)) +\n  geom_histogram(fill=\"blue4\") +\n  labs(x=\"Residuals\", y=\"Count\")\n```\n\nHow would you interpret this histogram of the residuals?\n\n```{r picker3, exercise=TRUE}\nsample(classroster$name, 1)\n```\n\n## $R^2$\n\n$R^2$ is just the return of $r$, the correlation coefficient. Remember:\n\n- $r$ measures the strength of the association between $x$ and $y$\n  + That is, how reliably $x$ varies with $y$\n\n- The correlation coefficient: `r round(cor(global.data$hdi.score, global.data$gdp.capita), digits=2)`\n- Our $R^2$: `r as.numeric(round(glance(hdi.model)[1], digits=2))`\n\n```{r rsquared, exercise=TRUE}\nglobal.data.nooutlier <- global.data %>%\n  filter(gdp.capita < 100000)\n\nhdi.model.nooutlier <- lm(hdi.score ~ gdp.capita, data=global.data.nooutlier)  \nglobal.data.augmented.nooutlier <- augment(hdi.model.nooutlier, global.data.nooutlier)\nhdi.model.tidy.nooutlier <- tidy(hdi.model.nooutlier)\n```\n\nWhat do you think the $R^2$ will change to when we remove the outlier?\n\n```{r picker4, exercise=TRUE}\nsample(classroster$name, 1)\n```\n\n- The correlation coefficient for a model with the outlier removed: \n\n```{r corroutlier, exercise=TRUE}\nround(cor(global.data.nooutlier$hdi.score, global.data.nooutlier$gdp.capita), digits=2)\n```\n\n- Our $R^2$ with the outlier removed: \n\n```{r rsquaredoutlier, exercise=TRUE}\nas.numeric(round(glance(hdi.model.nooutlier)[1], digits=2))\n```\n\n## How to interpret $R^2$\n\n- If there are no serious outliers and the relationship is linear, can provide a useful measure of how strongly the predictor variable is related to the response variable\n  + The two assumptions above are quite strong - you need to always draw a picture to make sure they are true!\n  + Should not be interpreted as how strongly $x$ *causes* $y$, we only know about association.\n\n## Regression assumptions\n\n- Quantitative variable assumption\n- Straight enough condition\n- Outlier condition\n- Does the plot thicken condition?\n\nHave we met these? \n\n```{r picker5, exercise=TRUE}\nsample(classroster$name, 1)\n```\n\n## Reexpressions\n\n### Log reexpressed\n\n```{r logreexpress, exercise=TRUE}\nglobal.data.log <- global.data %>%\n  mutate(log.gdp.capita = log(gdp.capita))\n\nhdi.model.log <- lm(hdi.score ~ log.gdp.capita, data=global.data.log)\nglobal.data.augmented.log <- augment(hdi.model.log, global.data.log)\nhdi.model.tidy.log <- tidy(hdi.model.log)\n```\n\nWhat will happen to the shape of the graph?\n\n```{r picker6, exercise=TRUE}\nsample(classroster$name, 1)\n```\n\n```{r logreexpressplot, exercise=TRUE}\nggplot(global.data.log, aes(x=log.gdp.capita, y=hdi.score)) +\n  geom_point() +\n  labs(x=\"Log of GDP per capita\", y=\"Human Development Index (HDI) score\") +\n  geom_smooth(method=\"lm\", se=FALSE)\n```\n\n### Log reexpressed - outlier\n\nAny guess as to the outlier?\n\n```{r picker7, exercise=TRUE}\nsample(classroster$name, 1)\n```\n\n```{r logoutlier, exercise=TRUE}\nggplot(global.data.log, aes(x=log.gdp.capita, y=hdi.score)) +\n  geom_point() +\n  labs(x=\"Log of GDP per capita\", y=\"Human Development Index (HDI) score\") +\n  geom_smooth(method=\"lm\", se=FALSE) +\n  geom_point(data=global.data.log %>% filter(log.gdp.capita > 9.5 & hdi.score < 0.61), color=\"red\") +\n  geom_text(data=global.data.log %>% filter(log.gdp.capita > 9.5 & hdi.score < 0.61), aes(label=Country), nudge_y = -0.03)\n```\n\n### Outlier\n\n```{r eqguinea1, fig.cap=\"Equatorial Guinea map\", out.width = \"400px\"}\nknitr::include_graphics(\"www/equatorial.guinea.map.jpg\")\n```\n\n```{r eqguinea2, fig.cap=\"Teodorin Nguema Obiang, the son of Equatorial Guinea's president Teodoro Obiang^[https://www.voanews.com/a/africa_supercars-houses-and-suits-equatorial-guineas-teodorin-obiang/6184016.html]\", out.width = \"400px\"}\nknitr::include_graphics(\"www/son.jpg\")\n```\n\n```{r eqguinea3, fig.cap=\"Teodorin's car collection\", out.width = \"400px\"}\nknitr::include_graphics(\"www/equatorial.guinea.cars.jpg\")\n```\n\n### Graphing the residuals - log\n\n```{r residualslog, exercise=TRUE}\nggplot(global.data.augmented.log, aes(log.gdp.capita, .resid)) + \n  geom_point() + \n  geom_hline(yintercept = 0, color = \"blue\", linetype='dashed') + \n  labs(y = \"Residuals\", x=\"Log of GDP per capita\")\n```\n\n### Residuals standard deviation - log\n\n```{r residualstddevlog, exercise=TRUE}\nggplot(global.data.augmented.log, aes(x=.resid)) +\n  geom_histogram(fill=\"blue4\") +\n  labs(x=\"Residuals\", y=\"Count\")\n```\n\n### $R^2$\n\n- The correlation coefficient: `r round(cor(global.data.log$hdi.score, global.data.log$log.gdp.capita), digits=2)`\n- Our $R^2$: `r as.numeric(round(glance(hdi.model.log)[1], digits=2))`\n\n### Regression assumptions\n\nFor the log reexpressed version, have the assumptions been met?\n\n- Quantitative variable assumption \n- Straight enough condition\n- Outlier condition\n- Does the plot thicken condition?\n\n```{r picker8, exercise=TRUE}\nsample(classroster$name, 1)\n```"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":{"learnr::tutorial":{"toc_depth":2}},"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"Simple Linear Regression.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.0.36","editor":"visual","theme":"cosmo","title":"Simple Linear Regression","subtitle":"DKU Stats 101 Spring 2022","author":"Professor MacDonald","date":"1/24/2022","runtime":"shiny_prerendered"},"extensions":{"book":{"multiFile":true}}}}}