{"title":"Confidence Intervals - Proportions","markdown":{"yaml":{"title":"Confidence Intervals - Proportions","subtitle":"DKU Stats 101 Spring 2022","author":"Professor MacDonald","date":"2/9/2021","output":{"learnr::tutorial":{"toc_depth":2}},"runtime":"shiny_prerendered"},"headingText":"Confidence Intervals","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE)\nknitr::opts_chunk$set(warning = FALSE)\nknitr::opts_chunk$set(message = FALSE)\n\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(broom)\nlibrary(gridExtra)\nlibrary(learnr)\n\ntheme_set(theme_classic())\n\nclassroster <- read.csv(\"www/classroster.csv\", fileEncoding=\"UTF-8-BOM\")\n\nset.seed(8675309)\nn.example <- 100\n\nmean.multiple.samples <- function(numdraws, numsamples, variable) { \n     meanvector <- c() \n     meanonesample <- 0 \n     for (i in 1:numsamples) { \n\t   meanonesample <- mean(sample(variable, numdraws, replace=TRUE)) \n         meanvector[i] <- meanonesample \n     } \n     meanvector \n}\n\nkc.house <- read.csv(\"www/kc.house.data.original.csv\")\n\nkc.house <- kc.house %>%\n  mutate(is.three.bedrooms = ifelse(bedrooms==3, 1, 0)) \n\nsampling.distribution <- mean.multiple.samples(100, 100000, kc.house$is.three.bedrooms)\nnormal.sampling.distribution <- rnorm(100000)\nskewed.population <- sample(c(1, 0), 100000, replace=TRUE, prob = c(0.001,0.999))\nskewed.sample <- mean.multiple.samples(100, 100000, skewed.population)\n\nsample.once <- sample(kc.house$is.three.bedrooms, 100, replace=TRUE)\np<-round(mean(sample.once), digits=3)\n```\n\n\n* The sampling distribution model for a proportion\n\n* When does the normal model work?\n\n* Confidence interval for a proportion\n\n* Interpreting confidence intervals\n\n* Margin of error: certainty vs. precision\n\n## The sampling distribution model for a proportion\n\n### Sampling model\n\n* Draw samples at random, $n=100$\n\n* Samples vary\n\n* Can’t draw all samples of size 100, astronomical\n\n* Draw a few thousand samples\n\n* Distribution is called the sampling distribution of the proportion.\n\nWhat shape do you think the sampling distribution will have if we have sample size $n=100$?\n\n```{r picker1, exercise=TRUE}\nsample(classroster$name, 1)\n```\n\n### Graph of a **sampling** distribution\n\n* Remember, this is not a graph of the **actual** distribution\n\n```{r samplingplot, exercise=TRUE}\nggplot(data.frame(sampling.distribution), aes(x=sampling.distribution)) +\n  geom_density(color=\"darkblue\", fill=\"lightblue\", adjust=2) + \n  labs(x=\"Sample mean of % of houses with 3 bedrooms\", y=\"Count\") +\n  geom_vline(xintercept=mean(sampling.distribution), color=\"red\") + \n  theme(axis.text.x = element_text(face=\"bold\", size=10))\n```\n\n### Random matters\n\n* Sampling distribution for a proportion\n\n  + Symmetric - check  \n\n  + Unimodal - check  \n\n  + Centered at $p$: **`r round(mean(sampling.distribution), digits=3)`** \n\n  + Standard deviation: **`r round(sd(sampling.distribution), digits=3)`**\n\n  + Follows the Normal model - check  \n\n### The Normal model for sampling\n\n* Samples don’t all have the same proportion.\n\n* Normal model is the right one for sample proportions.\n\n* Modeling how sample statistics, proportions or means, vary from sample to sample is powerful.\n\n* Allows us to quantify that variation.\n\n* Make statements about corresponding population parameter.\n\n* Make model for random behavior, then understand and and use that model.\n\n### Whicn Normal model to choose?\n\n* Reminder: normal model is $N(\\mu, \\sigma^2)$\n\n* $\\mu$ or mean is $p$, or the proportion we want to estimate, $n$ is sample size\n\n* For proportions, $\\sigma(p) = \\sqrt{\\frac{p(1-p)}{n}}$\n\n* This is the standard deviation of the **SAMPLING DISTRIBUTION**, that is the distribution of $p$ across infinite samples\n\n### Mean and standard deviation\n\n```{r meansdplot, exercise=TRUE}\nggplot(data.frame(normal.sampling.distribution), aes(x=normal.sampling.distribution)) + \n  geom_density(color=\"darkblue\", fill=\"lightblue\") +\n  scale_x_continuous(breaks=c(-3, -2, -1, 0, 1, 2, 3),\n                     label=c(\"-3sqrt(pq/n)\", \"-2sqrt(pq/n)\", \"-1sqrt(pq/n)\", \"0sqrt(pq/n)\", \"1sqrt(pq/n)\", \"2sqrt(pq/n)\", \"3sqrt(pq/n)\"), \n                     limits=c(-3, 3),\n                     guide = guide_axis(n.dodge=2)) +\n  labs(x=\"Normal model distances for proportions\", y=\"Density\") + \n  theme(axis.text.x = element_text(face=\"bold\", size=10))\n```\n\n### Reminder - Normal model rule\n\n* Using this normal model rule, we can tell how likely it is to have a certain $\\hat{p}$ given the sampling distribution normal model\n\n* Remember the 68–95–99.7 (1 sd, 2 sd, 3 sd), for other distances use technology\n\n* Most common: 95% of samples have sample proportion within two standard deviations of the true population proportion.\n\n* Knowing the sampling distribution tells us how much variation to expect\n\n* Called the sampling error in some contexts\n\n* Not really an error, just variability\n\n* Better to call it sampling variability\n\n## When does the normal model work?\n\n* Independence Assumption: check data collected in a way that makes this assumption plausible\n\n* Randomization Condition: subjects randomly assigned treatments, or survey is simple random sample\n\n* 10% Condition: sample size less than 10% of the population size\n\n* Success Failure Condition: there must be at least 10 expected successes and failures. $n\\hat{p}\\geq10$ and $\\hat{n}p\\geq10$\n\n### When does the normal model fail for the sampling distribution?\n\n* $p$ close to 0 or 1\n\n* People in this class that can dunk a basketball\n\n* Sample size 100\n    + If true $p = 0.001$, then probably none in sample of 100\n\n* If we simulated samples of size 100 with $p = 0.001$\n    + Distribution skewed right, can't rely on normal model percentages anymore\n    \n* $n$ is fine, but $p$ is too small\n\nWhat will the shape of the sampling distribution look like if $p = 0.001$?\n\n```{r picker2, exercise=TRUE}\nsample(classroster$name, 1)\n```\n\n### Example simulation\n\n```{r skewsamplingplot, exercise=TRUE}\nggplot(data.frame(skewed.sample), aes(x=skewed.sample)) +\n  geom_density(color=\"darkblue\", fill=\"lightblue\") + \n  labs(x=\"Sample mean of those who can dunk with sample size = 100\", y=\"Count\")\n```\n\n### Class sampling exercise\n\n* We know that about 50% of students at DKU plan to or have selected a major in the natural sciences\n\n* ? % of students in our class plan to major in the natural sciences in our class\n  + Is our class unusually small?\n  \n* Check conditions\n  + Randomization condition\n  + 10% condition\n  + Success failure condition\n  \n### Find how far we are from the population mean\n\n* Population standard deviation formula is:\n  + $\\frac{\\sqrt{p(1-p)}}{\\sqrt{n}}$\n  + $\\hat{p}$ is the proportion of yeses\n  + $n$ is the sample size\n  \n* We are calculating using the population **sampling** $SD$ since we know it\n  + If we don't know the population sampling $SD$ we have to use a different strategy, but not the case here\n\n* Knowing the $SD$, we can create a z score for the difference between our class and the population\n  + z score is how many $SD$s our class is from the population mean\n    - $(class score - dkumean) / SD$\n\n### Normal distribution percentages\n\n```{r normalpercentiles, exercise=TRUE}\nggplot(data.frame(normal.sampling.distribution), aes(x=normal.sampling.distribution)) + \n  geom_density(color=\"darkblue\", fill=\"lightblue\") +\n  scale_x_continuous(breaks=c(-3, -2, -1, 0, 1, 2, 3),\n                     label=c(\"~0.005\", \"~0.025\", \"~0.16\", \"0.5\", \"~0.84\", \"~0.95\", \"~0.995\"), \n                     limits=c(-3, 3),\n                     guide = guide_axis(n.dodge=2)) +\n  labs(x=\"Cumulative density\", y=\"Density\") +\n  theme(axis.text.x = element_text(face=\"bold\", size=10))\n```\n\n### Calculation for our class\n\n* $\\frac{\\sqrt{p(1-p)}}{\\sqrt{n}}$\n\n* $\\hat{p}$ is the proportion of yeses\n\n* $n$ is the sample size\n\n* $\\frac{\\hat{p} - p}{SD(p)}$ \n\n* 68-95-99.7 Rule:  Values ?$SD$ above the mean occur less than ?% of the time. Our class mean appears to be far/near from the population mean\n\nCalculate the how likely our result would be if our class is a random sample of DKU students.\n\n```{r picker3, exercise=TRUE}\nsample(classroster$name, 1)\n```\n\n## Confidence intervals of proportions\n\n### Standard errors for proportions\n\n* What is the sampling distribution?\n\n* Usually we do not know the population proportion $p$.\n\n* Therefore, we cannot find the standard deviation of the sampling distribution $\\frac{\\sqrt{p(1-p)}}{\\sqrt{n}}$\n\n* After taking a sample, we only know the sample proportion, which we use as an approximation (called the standard error)\n  + $\\frac{\\sqrt{\\hat{p}(1-\\hat{p})}}{\\sqrt{n}}$\n\n### Example: bedrooms\n\n* Draw a random sample of 100 houses\n\n```{r randomsample, exercise=TRUE}\n#sample.once <- sample(kc.house$is.three.bedrooms, 100, replace=TRUE)\n#p<-round(mean(sample.once), digits=3)\n\np\n```\n \n* $\\frac{\\sqrt{\\hat{p}(1-\\hat{p})}}{\\sqrt{100}}$\n\n* The sampling distribution should be approximately normal\n\n### What is a confidence interval?\n\n* Confidence interval: a way to express the range of plausible values for the parameter (in this case, percent of homes with three bedrooms)\n\n* We never know the true value but we want to say something about how wide the range of possible values are\n\n* What is a reasonable range?\n  + Traditionally, 95% (about two standard deviations) of the standard error distribution\n  + Mean of our sample $\\pm$ range of possible values we could get if we took additional samples\n\n### Example: bedrooms\n\n* Our mean: `r round(mean(sample.once), digits=3)`\n\n* Our **estimated** sampling distribution standard error: \n  + $\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{`r n.example`}}$\n  + $\\sqrt{\\frac{\\hat{`r p`}(1-\\hat{`r p`})}{`r n.example`}}$\n  + $\\sqrt{\\frac{`r p*p`}{100}}$\n  + $\\sqrt{`r p*p/100`}$\n  + $`r sqrt(p*p/100)`$\n  \n* A range of reasonable values if we sampled this again:\n  + $2\\times`r sqrt(p*p/100)`$\n  + $`r p`\\pm`r 2*sqrt(p*p/100)`$\n\nStatement: we are ~95% confident that this interval contains the true proportion of houses with three bedrooms in the population\n\n### Critical values\n\n* Critical values are the cutoff we use to determine what is 'reasonable'\n\n* Derived from the Normal model\n\n* Can use any z-score as a cutoff\n\n* Corresponding multiplier of the SE is called the critical value.\n\n* Normal model for this interval, it is denoted $z^*$.\n\n* To find, need to use computer, calculator, Normal probability table\n\n```{r normpercents, exercise=TRUE}\nqnorm(c(0.025, 0.975))\n```\n \n### Recap\n\n* Make sure conditions are met, then find level C confidence interval for $\\hat{p}$, our population mean estimate\n\n* Confidence interval is defined as $\\hat{p}\\pm z^* \\times SE(\\hat{p})$\n\n* $SE(\\hat{p})$ estimated by $\\frac{\\sqrt{\\hat{p}(1-\\hat{p})}}{\\sqrt{n}}$\n\n* $z^*$ specifies number of SEs needed for C% of random samples to yield confidence intervals that capture the true parameter\n\n### What you cannot say about $p$ from the sample\n\n1. \"`r p` of all houses in King County have three bedrooms.\" \n  + No. Observations vary. Another sample would yield a different sample proportion.\n\n2. \"It is probably true that `r p` of all houses in King County have three bedrooms.\" \n  + No again. In fact, even if we didn’t know the true proportion, we’d know that it’s probably not `r p`.\n\n### What you cannot say about $p$ from the sample\n\n3. \"We don’t know exactly what proportion of houses in King County have three bedrooms, but we know that it’s within the interval $`r p`\\pm2\\times`r sqrt(p*p/100)`$.”   \n  + No but getting closer. We don't know this for sure. \n  \n4. \"We don’t know exactly what proportion of houses in King County have three bedrooms, but the interval from `r round((p-(2*sqrt(p*p/100))), digits=3)` to `r round((p+(2*sqrt(p*p/100))), digits=3)` probably contains the true proportion.\"\n  + Right but can be more precise. We should specify how confident we are not just say *probably*\n  \n### What you can say about $p$ from the sample\n\n5. \"We are 95% confident that between `r round((p-(2*sqrt(p*p/100))), digits=3)` and `r round((p+(2*sqrt(p*p/100))), digits=3)` of houses in King County have three bedrooms.\" \n  + Statements like these are called confidence intervals. They’re the best we can do.\n\n### Naming the confidence interval\n\n* This confidence interval is a one-proportion z-interval.\n\n  + \"One\" since there is a single mean being calculated.\n  + \"Proportion\" since we are interested in the proportion of the population.\n  + \"z-interval\" since the distance of the interval relies on a normal sampling distribution model.\n\n## Interpreting confidence intervals\n\n### Capturing a proportion\n\n* The confidence interval may or may not contain the true population proportion.\n\n* Consider repeating the study over an over again, each time with the same sample size.\n\n* Each time we would get a different $\\hat{p}$\n\n* From each $\\hat{p}$, a different confidence interval could be computed.\n\n* About 95% of these confidence intervals will capture the true proportion.\n\n* 5% will be duds.\n\n### Random matters - confidence intervals\n\n* There are a huge number of confidence intervals that could be drawn.\n\n* In theory, all the confidence intervals could be listed.\n    + 95% will “work” (capture the true proportion).\n    + 5% will be “duds” (not capture the true proportion).\n    \n* What about our confidence interval (`r round((p-(2*sqrt(p*p/100))), digits=3)`, `r round((p+(2*sqrt(p*p/100))), digits=3)`)?\n    + In this case, we can find out the true value \n    + Most of the time we never know\n\n```{r truemean, exercise=TRUE}\nmean(kc.house$is.three.bedrooms)\n```\n\n### Random matters - confidence intervals\n\n![100 samples CI](www/multi.ci.png)\n\n## Margin of error: certainty vs. precision\n\n### Margin of error\n\n* Confidence interval for a population proportion: $\\hat{p} \\pm 2\\times SE(\\hat{p})$\n\n* The distance, $~2\\times SE(\\hat{p})$, from $\\hat{p}$ is called the *margin of error*\n\n* Confidence intervals can be applied to many statistics, not just means. Regression slopes and other quantities can also have confidence intervals.\n\n  + In general, a confidence interval has the form **estimate** $\\pm$ **margin of error**\n\n### Certainty vs. precision\n\n* Competing goals\n  + More certainty, need to capture $p$ more often, need to make the interval wider.\n  + More precise, need to provider tighter bounds on our estimate for $p$, need to make the interval narrower\n\n* Instead of a 95% confidence interval, any percent can be used.\n  + Increasing the confidence (e.g. 99%) increases the margin of error.\n    - Need to make our range wider to make sure we don't 'miss' \n  + Decreasing the confidence (e.g. 90%) decreases the margin of error.\n    - Need to make our range smaller so as to be more specific about our guess\n\n### What sample size?\n\n* Can increase both certainty and precision by increasing sample size\n\n* For 95%, $z^*$ = 1.96\n\n* Values that make ME largest are $\\hat{p}=0.5$\n\n* If we want to ensure, say, a **margin of error** of $<3%$\n  + $ME = z\\times \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$\n  + $0.03 = 1.96\\times \\sqrt{\\frac{(0.5)(0.5)}{n}}$\n  \n* Solving for $n$, gives $n\\approx1067.1$\n\n* We need to survey at least 1068 to ensure a ME less than 0.03 for the 95% confidence interval.\n\n### Thoughts on sample size and ME\n\n* Obtaining a large sample size can be expensive and/or take a long time.\n\n* For a pilot study, $ME = 10%$ can be acceptable.\n\n* For full studies, $ME < 5%$ is better.\n\n* Public opinion polls typically use $ME = 3%$, $n = 1000$\n\n* If $p$ is expected to be very small such as 0.005, then much smaller ME such as 0.1% is required.\n  + Common in medical studies\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":{"learnr::tutorial":{"toc_depth":2}},"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"Confidence Intervals - Proportions.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.0.36","editor":"visual","theme":"cosmo","title":"Confidence Intervals - Proportions","subtitle":"DKU Stats 101 Spring 2022","author":"Professor MacDonald","date":"2/9/2021","runtime":"shiny_prerendered"},"extensions":{"book":{"multiFile":true}}}}}